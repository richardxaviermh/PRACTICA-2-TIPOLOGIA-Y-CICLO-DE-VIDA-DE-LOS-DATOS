---
title: "Práctica 2: Limpieza y Análisis de Datos"
author: "Richard Jácome - Andrea Martínez"
date: "Junio 2021"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# . Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

******

El dataset a ser utilizado en esta práctica ha sido obtenido de la página de Kaggle y se puede acceder en el siguiente link: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset    

Este dataset contiene información para predecir si un paciente tiene la probabilidad de sufrir un accidente cerebral vascular (AVC) basado en ciertas características como género, edad, ciertas enfermedades, etc.

De acuerdo a la Organización Mundial de la Salud, las enfermedades cardiovasculares son la principal causa de muerte en todo el mundo, dentro de las cuales se encuentran los ataques al coración y los AVC. https://www.who.int/es/news-room/fact-sheets/detail/cardiovascular-diseases-(cvds)

Es importante este dataset ya que permite analizar si cierto grupo de pacientes tiene mayor incidencia a sufrir AVC en comparación con otro y en base a esta predisposición se pueden definir políticas de medicina preventiva para evitar la ocurrencia de un derrame.

******
# . Integración y selección de los datos de interés a analizar. 

******

Los datos están contenidos en un solo dataset en formato csv con la siguiente estructura:

```{r message= FALSE, warning=FALSE}
#Cargamos el archivo  respectivo
df_stroke <- read.csv("healthcare-dataset-stroke-data.csv", header=T, sep=",", stringsAsFactors = TRUE, encoding = "UTF-8")
#Verificamos la estructura del archivo
str(df_stroke)
```

Podemos observar que el dataset contiene 5.110 observaciones con 12 variables de las cuales 6 variables son numéricas y 6 categóricas. La variable objetivo es "stroke" que puede tomar valores 0 o 1

Para efectos de este análisis de van a utilizar todas las variables proporcionadas en el dataset.


******
# . Limpieza de Datos. 

******

******
# Análisis de los datos
******
## . ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos? 

******

Primero verificamos el resumen de los datos:

```{r message= FALSE, warning=FALSE}
# Estadísticas de valores NA
summary(df_stroke)
```

Podemos apreciar que la variable bmi tiene valores N/A que deben ser saneados.

```{r message= FALSE, warning=FALSE}
# Estadísticas de valores NA
colSums(is.na(df_stroke))
```

Se puede apreciar que no existen valores NA.


```{r message= FALSE, warning=FALSE}
# Estadísticas de valores vacíos
colSums(df_stroke=="")
```

También se comprueba que no hay datos vacíos.

Sabemos que bmi contiene valores NA, si embargo no se visualiza con los procesos ejecutados anteriormente, esto se debe que está en tipo factor, por lo cual se lo debe pasar atributo numérico para poder imputar valores.

```{r message= FALSE, warning=FALSE}
library(varhandle)
df_stroke$bmi <- unfactor(df_stroke$bmi)
df_stroke$bmi <- as.double(df_stroke$bmi)
```

```{r message= FALSE, warning=FALSE}
# Estadísticas de valores NA
colSums(is.na(df_stroke))
```


Para reemplazar los valores perdidos utilizaremos el método kNN, que se basa en los k vecinos más próximos de acuerdo con los valores de los registros.

```{r message= FALSE, warning=FALSE}
# Imputación de valores mediante la función kNN() del paquete VIM
suppressWarnings(suppressMessages(library(VIM)))
df_stroke$bmi <- kNN(df_stroke)$bmi
```

```{r message= FALSE, warning=FALSE}
# Estadísticas de valores NA
colSums(is.na(df_stroke))
```

Volvemos a analizar los valores NA y ya no están presentes.

******
## .  Identificación y tratamiento de valores extremos.

******

```{r message= FALSE, warning=FALSE}
# número de variantes por variable del data frame
apply(df_stroke,2, function(x) length(unique(x)))
```

Primero verificamos cuantas variantes tenemos en los atributos para buscar outliers, donde se tenga una cantidad alta de variantes, por lo cual analizaremos los atributos: age, avg_glucose_level y bmi, id no se toma en cuenta, ya que solo es un identificador.

Vamos a representar la distribución de los valores de las variables para visualizar picos atípicos que se tomarán como inconsistencias:

```{r message= FALSE, warning=FALSE}
library(ggplot2)
ggplot(mapping= aes(x=df_stroke$age))+ geom_density()
```

En el atributo age podemos evidenciar que se tiene una tendencia a la normalidad y visualizan variaciones diferentes en los extremos que no necesariamente son valores atípicos por lo cual verificaremos con boxplot.

```{r message= FALSE, warning=FALSE}
boxplot.stats(df_stroke$age)$out
```

Se confirma que la variable age no contiene valores atípicos.

```{r message= FALSE, warning=FALSE}
library(ggplot2)
ggplot(mapping= aes(x=df_stroke$avg_glucose_level))+ geom_density()
```

Se puede evidenciar en la gráfica que los datos tienden a la normalidad, en el extremos derecho se tiene una curva con valores que no siguen la tendencia, sin embargo no justican ser atípicos.

```{r message= FALSE, warning=FALSE}
(boxplot.stats(df_stroke$avg_glucose_level)$out)
```

Al comprobar con boxplot nos arroja todos lo valores altos de los datos, ya que no siguen el patrón de la normal, sin embargo, los datos no son erróneos, por lo cual no se los debe modificar o quitar.

```{r message= FALSE, warning=FALSE}
library(ggplot2)
ggplot(mapping= aes(x=df_stroke$bmi))+ geom_density()
```

Al igual que los atributos analizados anteriormente, se tiene una normal y cuando llega a valores altos queda fuera de tendencia, por lo cual se comprueba con boxplot:

```{r message= FALSE, warning=FALSE}
boxplot.stats(df_stroke$bmi)$out
```

Una vez comprobamos que con valores altos los datos no siguen con la tendencia normal, sin embargo no indica que los valores son atípicos o frutos del error, sino que pertenecen a personas con características diferentes al promedio.


******
# . Análisis de los Datos. 

******


******
## . Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).


******

******
## .  Comprobación de la normalidad y homogeneidad de la varianza.

******

******
## .  Aplicación de pruebas estadísticas para comparar los grupos de datos. 

******

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes. 

******
# . Representación de los resultados a partir de tablas y gráficas.

******

******
# . Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

******